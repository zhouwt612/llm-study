# LLM Study: From theory to implementation

## *Note: The recommended part is labeled with ðŸŒŸ.*

### 1. **Programming**
#### (1) [**LangChain**ðŸŒŸðŸŒŸ](https://python.langchain.com/docs/tutorials/)
#### (2) [**Groq**ðŸŒŸ](https://console.groq.com/docs/quickstart)

### 2. **Cloud Services (API Keys)**
#### (1) [**OpenAI API**](https://openai.com/index/openai-api/)
#### (2) [**Groq API**ðŸŒŸ](https://console.groq.com/)

### 3. **(Optional) Local Deployment** 

*A good computer is required to implement the local deployment. Let us consider the deployment based on the API key first.*

#### (1) [**Hugging Face Transformers**](https://huggingface.co/)
#### (2) [**Ollama (Meta)**](https://ollama.com/)

### 4. **Prompt Engineering**
#### (1) [**Prompt Engineering Guide**](https://www.promptingguide.ai/)

### 5. **Videos**
#### (1) [**Llama 3.1 API using Groq**](https://www.youtube.com/watch?v=QSyRoOO4pXE)
*I am not sure whether the API key on Groq is totally free. Let us start with some cheap models, e.g., Llama 3.1 8b Instant and Llama3 8b 8192*

### 6. **Related links**
#### (1) [**Colab**](https://colab.google/)
#### (2) [**Lilâ€™Log**](https://lilianweng.github.io/)

